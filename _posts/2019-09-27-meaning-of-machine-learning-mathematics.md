---
layout: post
title:  What does it really mean for a machine to learn mathematics?
date:   2019-09-27
categories: math
tags: ['machine learning', math, 'neural netowrks']
---

This post was triggered by a paper [posted here](https://openreview.net/pdf?id=S1eZYeHFDS), titled "Deep learning from symbolic mathematics". The authors trained a sequence-to-sequence neural network that was able to perform symbolic integration and solve differential equations. Remarkably, they achieved results that outperform commercial Computer Algebra Systems (CAS) such as Matlab and Mathematica.

The training set for integration was generated by starting with random functions (with a certain upper bound in terms of their length) and calculated their derivative with a CAS. Then the derivative became the input target and the original function the output. For instance, suppose that we start with the function

$$
f(x) = \ln(\ln(x)) \Rightarrow f'(x) = \frac{1}{\ln(x)} \cdot (\ln(x))' = \frac{1}{x \ln(x)}
$$

Then, in our training set we consider $$\frac{1}{x \ln(x)}$$ the input, i.e. the function that we want to integrate, and $$\ln(\ln(x))$$ the desired output of our model. 
