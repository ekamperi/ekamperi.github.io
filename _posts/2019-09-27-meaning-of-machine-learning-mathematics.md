---
layout: post
title:  What does it really mean for a machine to learn mathematics?
date:   2019-09-27
categories: math
tags: ['machine learning', math, 'neural netowrks']
---

### Introduction
This post was triggered by a paper [posted here](https://openreview.net/pdf?id=S1eZYeHFDS), titled "Deep learning from symbolic mathematics". The authors trained a sequence-to-sequence neural network that was able to perform symbolic integration and solve differential equations. Remarkably, they achieved results that outperform commercial Computer Algebra Systems (CAS) such as [Matlab](https://www.mathworks.com/products/matlab.html) and [Mathematica](https://www.wolfram.com/mathematica/).

### Integration
The training set for integration was generated by starting with random functions (with a certain upper bound in terms of their length) and calculating their derivative with a CAS. Then the derivative becomes the input target and the original function the output. For instance, suppose that we start with the function:

$$
f(x) = \ln(\ln(x)) \Rightarrow f'(x) = \frac{1}{\ln(x)} \cdot (\ln(x))' = \frac{1}{x \ln(x)}
$$

Then, in our training set we consider $$\frac{1}{x \ln(x)}$$ as the input, i.e. the function that we want to integrate, and $$\ln(\ln(x))$$ becomes the desired output of our model.

$$
\int \frac{1}{x \ln(x)} = \ln(\ln(x)) + C
$$

### Solving first order differential equations
The training set for solving first order differential equations is generated in a similar way as previously, i.e. with a "reverse logic". Let's start with a random function of two variables $$F(x,y) = c$$, where $$c$$ is constant. Then if $$F$$ is chosen such that it is "solvable for $$y$$", meaning that we can write $$y = f(x, c) = f_c(x)$$, the function $$F$$ can be expressed as $$F(x, f_c(x)) = c$$. If we differentiate with respect to $$x$$, we get:

$$
\frac{\partial F(x, f_c(x))}{\partial x} + \frac{\partial F(x,f_c(x))}{\partial f_c(x)} \frac{\partial f_c(x)}{\partial x} = 0
$$

Recall that when we want to calculate the *total derivative* of a function $$y = f(t, u_1, u_2, \ldots)$$, where the intermediate variables $$u_k$$ are functions of the form $$u_k = u_k(t, u_1, u_2, \ldots)$$, then $$\frac{\partial y}{\partial t} = \frac{\partial f}{\partial t} + \frac{\partial f}{\partial u_1}\frac{\partial u_1}{\partial t} + \ldots$$, since $$y$$'s value are affected directly by $$t$$ but also indirectly via the intermediate variables $$u_k$$ that are functions of $$t$$ as well.
